{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MichalKucko/NLP/blob/master/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5ouvU9EwFE_",
        "colab_type": "code",
        "outputId": "c11bfe6e-2ff7-4586-e85b-60555b7efaba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats.stats import pearsonr  \n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM, Embedding, Bidirectional\n",
        "from gensim.models import FastText\n",
        "from gensim.utils import tokenize\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn import svm\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4bGyOQira-S",
        "colab_type": "code",
        "outputId": "04c65d1d-81d6-41e5-9475-d5dc1cd40b1e",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 39
        }
      },
      "source": [
        "# załadowanie plików z danymi\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-74d81bce-f7e7-413a-96bc-b6beb177d90d\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-74d81bce-f7e7-413a-96bc-b6beb177d90d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCO8ULk_8cPF",
        "colab_type": "code",
        "outputId": "f8644c73-27e3-4b3c-f4d0-08c7ec67798e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# ściągnięcie i rozpakowanie wektorów FastText\n",
        "!curl -o cc.pl.300.bin.gz https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.pl.300.bin.gz\n",
        "!gunzip cc.pl.300.bin.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 4294M  100 4294M    0     0  39.1M      0  0:01:49  0:01:49 --:--:-- 17.7M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTMH-ejYmcE_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# wczytanie danych\n",
        "with open('training_set_clean_only_text.txt', 'r') as f:\n",
        "  train_text = f.readlines()\n",
        "with open('test_set_clean_only_text.txt', 'r') as f:\n",
        "  test_text = f.readlines()\n",
        "train_tags = np.loadtxt('training_set_clean_only_tags.txt', dtype=int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbpPwr4jqawq",
        "colab_type": "code",
        "outputId": "43d8a141-f7a1-49c5-8316-65b91455fa6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# baseline - losowanie klasy na podstawie ich częstości w zbiorze uczącym\n",
        "freq0 = len(train_tags[train_tags==0])/len(train_tags)\n",
        "print('Odsetek próbek klasy 0:', freq0)\n",
        "out = ['0\\n' if np.random.uniform() < freq0 else '1\\n' for i in range(len(test_text))]\n",
        "with open('resultsBaseline.txt', 'w') as f:\n",
        "  f.writelines(out)\n",
        "files.download('resultsBaseline.txt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Odsetek próbek klasy 0: 0.915247485310228\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBsKDe2kwDQi",
        "colab_type": "code",
        "outputId": "dab32b14-717f-48b6-cc95-dc6313c6d203",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# wczytanie modelu wektorów FastText\n",
        "vecModel = FastText.load_fasttext_format('cc.pl.300')\n",
        "print(\"zmieniłam\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "zmieniłam\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzzeIFLtZDDZ",
        "colab_type": "code",
        "outputId": "720ff0f8-bd77-40cf-e34b-26f8e2af841b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "# zamiana zdań na wektory (średnia z wektorów słów)\n",
        "def text2Vectors(text, vecLen = 300):\n",
        "  errs=[]\n",
        "  sentVecs = np.zeros((len(text), vecLen))\n",
        "  for i in range(len(text)):\n",
        "    tokens = list(tokenize(text[i], lowercase = True))   # usuwa liczby i interpunkcję\n",
        "    vec = np.zeros(vecLen)\n",
        "    cnt = 0\n",
        "    for token in tokens:\n",
        "      if token == 'anonymized_account':  \n",
        "        continue\n",
        "      try:\n",
        "        vec += vecModel.wv[token]#wv[token] - zamienia słowo na wektor\n",
        "        cnt += 1\n",
        "      except KeyError:\n",
        "        errs.append(token)\n",
        "        continue\n",
        "    sentVecs[i,] = vec / cnt if cnt else np.zeros(vecLen)\n",
        "  return sentVecs, errs\n",
        "\n",
        "sentVecsTrain, errs = text2Vectors(train_text)\n",
        "#sentVecsTrain, errs = text2Vectors(test_text)\n",
        "sentVecsTest, errs = text2Vectors(test_text)\n",
        "sentVecsTest"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.04223325,  0.02780653, -0.03056183, ..., -0.03986559,\n",
              "         0.01298455, -0.02628536],\n",
              "       [-0.05724153,  0.04636027,  0.00597388, ..., -0.02015102,\n",
              "         0.03325379,  0.01044905],\n",
              "       [-0.02283935,  0.01472753,  0.00771505, ..., -0.0156786 ,\n",
              "         0.04276353,  0.00952874],\n",
              "       ...,\n",
              "       [-0.01292548, -0.02146565,  0.00168017, ...,  0.04769662,\n",
              "        -0.01327721, -0.00341588],\n",
              "       [ 0.00940409, -0.00143855, -0.01415663, ...,  0.03220999,\n",
              "         0.00415251,  0.01734362],\n",
              "       [-0.01103416,  0.01442292,  0.02303123, ...,  0.01034418,\n",
              "         0.05392634, -0.05866718]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cutStIP-DdE9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PCA na wektorach\n",
        "newVecLen = 50\n",
        "#tsneModel = TSNE(perplexity=40, n_components=ncomponents, init='pca', metric=metric, n_iter=2500, random_state=23)  # można zobaczyć, czy TSNe lepsze od PCA\n",
        "pcaModel = PCA(n_components=newVecLen)\n",
        "pcaSentVecsTrain = pcaModel.fit_transform(sentVecsTrain)\n",
        "pcaSentVecsTest = pcaModel.transform(sentVecsTest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Xc6W3Z09gTU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# bag of words\n",
        "vectorizer = CountVectorizer()\n",
        "bags_train = vectorizer.fit_transform(train_text)\n",
        "bags_test = vectorizer.transform(test_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9L-V0P_D82L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SVM na wektorach albo bags of wordsach\n",
        "#svmModel = svm.SVC(class_weight = {0:0.1, 1:0.9}, C = 1000, gamma='auto') # class_weight = {0:0.1, 1:0.9} - jaką wagę przykłada do poszczególnych klas\n",
        "#svmModel.fit(sentVecsTrain, train_tags)\n",
        "#svmModel.fit(pcaSentVecsTrain, train_tags)\n",
        "#svmModel.fit(bags_train, train_tags)\n",
        "preds = svmModel.predict(sentVecsTest)\n",
        "#preds = svmModel.predict(pcaSentVecsTest)\n",
        "#preds = svmModel.predict(bags_test)\n",
        "np.savetxt('resultsSVM.txt', preds, fmt='%d')\n",
        "files.download('resultsSVM.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a71Lk31wLJDY",
        "colab_type": "code",
        "outputId": "dcddb3b9-a178-4e0e-9ad1-8d1ce2a2a2c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# dla każdego przykładu zwraca, ile było słów spoza słownika\n",
        "def getMistakeCnts(text):\n",
        "  cntVec = np.zeros(len(text))\n",
        "  for i in range(len(text)):\n",
        "    tokens = list(tokenize(text[i], lowercase = True))   #wywala liczby\n",
        "    cnt = 0\n",
        "    for token in tokens:\n",
        "      if token == 'anonymized_account':\n",
        "        continue\n",
        "      if (token not in vecModel.wv.vocab):\n",
        "        cnt += 1\n",
        "    cntVec[i] = cnt\n",
        "  return cntVec\n",
        "  \n",
        "mistakesVec_train = getMistakeCnts(train_text)\n",
        "mistakesVec_test = getMistakeCnts(test_text)\n",
        "print(sum(mistakesVec_train != 0), '/', len(train_text), 'zdań z błędami na zbiorze uczącym')\n",
        "print(pearsonr(mistakesVec_train, train_tags))   # korelacji raczej nie ma"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2954 / 10041 zdań z błędami na zbiorze uczącym\n",
            "(0.01720474005221367, 0.08472403401794718)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_l7HQeOcN6TT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SVM na liczbach błędów\n",
        "svmModel = svm.SVC(class_weight = {0:0.1, 1:0.9}, C = 1000, gamma='auto')\n",
        "svmModel.fit(mistakesVec_train.reshape(-1, 1), train_tags)\n",
        "preds = svmModel.predict(mistakesVec_test.reshape(-1, 1))\n",
        "np.savetxt('resultsSVM.txt', preds, fmt='%d')\n",
        "files.download('resultsSVM.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qdvSjrfBVB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sieć LSTM, która sama będzie uczyć się wektorów słów\n",
        "\n",
        "maxLen = 40   # maksymalna długość zdania\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_text)\n",
        "train_seqs = tokenizer.texts_to_sequences(train_text)\n",
        "#maxLen = max([len(x) for x in train_seqs])\n",
        "train_seqs = pad_sequences(train_seqs, padding='post', maxlen=maxLen)\n",
        "\n",
        "embeddingDim = 50   # długość wektorów\n",
        "lstmModel = Sequential()\n",
        "lstmModel.add(Embedding(len(tokenizer.word_index) + 1, embeddingDim, input_length=maxLen))# uczy się wektorów słów z integerów\n",
        "lstmModel.add(LSTM(embeddingDim))# wlasciwa siec rekur\n",
        "lstmModel.add(Dropout(0.5))   # można zobaczyć różne wartości, wywala 0.5 wyjsc z sieci, zeby sie nie przeuczala\n",
        "lstmModel.add(Dense(1, activation='sigmoid'))# funkcja aktywacji\n",
        "lstmModel.compile(optimizer='adam', loss='binary_crossentropy')#cos tam optymalizuje\n",
        "lstmModel.summary()\n",
        "history = lstmModel.fit(train_seqs, train_tags, epochs=30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSXqolVV_Ql8",
        "colab_type": "code",
        "outputId": "4f5cd27d-76c2-47ce-8d0d-a7c23697911e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 654
        }
      },
      "source": [
        "# sieć LSTM z wyuczonymi wektorami słów (FastText)\n",
        "\n",
        "maxLen = 40   # maksymalna długość zdania\n",
        "embeddingDim = 300   # długość wektorów (taka jest w FastText)\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_text)\n",
        "train_seqs = tokenizer.texts_to_sequences(train_text)\n",
        "#maxLen = max([len(x) for x in train_seqs])\n",
        "train_seqs = pad_sequences(train_seqs, padding='post', maxlen=maxLen)\n",
        "\n",
        "embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, embeddingDim))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "  try:\n",
        "    vector = vecModel.wv[word]\n",
        "    embedding_matrix[index] = vector\n",
        "  except KeyError:\n",
        "    continue\n",
        "\n",
        "newEmbeddingDim = 50    # długość wektorów po PCA\n",
        "pcaModel = PCA(n_components=newEmbeddingDim)\n",
        "embedding_matrix_pca = pcaModel.fit_transform(embedding_matrix)\n",
        "\n",
        "#embedding_matrix_pca=embedding_matrix\n",
        "    \n",
        "lstmModel = Sequential()\n",
        "lstmModel.add(Embedding(len(tokenizer.word_index) + 1, newEmbeddingDim, input_length=maxLen, weights=[embedding_matrix_pca], trainable=False))\n",
        "lstmModel.add(LSTM(newEmbeddingDim))\n",
        "lstmModel.add(Dropout(0.5))\n",
        "lstmModel.add(Dense(1, activation='sigmoid'))\n",
        "lstmModel.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "lstmModel.summary()\n",
        "history = lstmModel.fit(train_seqs, train_tags,epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 40, 300)           7020900   \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 300)               721200    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 301       \n",
            "=================================================================\n",
            "Total params: 7,742,401\n",
            "Trainable params: 721,501\n",
            "Non-trainable params: 7,020,900\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "10041/10041 [==============================] - 89s 9ms/step - loss: 0.3059\n",
            "Epoch 2/10\n",
            "10041/10041 [==============================] - 88s 9ms/step - loss: 0.2963\n",
            "Epoch 3/10\n",
            "10041/10041 [==============================] - 89s 9ms/step - loss: 0.2939\n",
            "Epoch 4/10\n",
            "10041/10041 [==============================] - 89s 9ms/step - loss: 0.2942\n",
            "Epoch 5/10\n",
            "10041/10041 [==============================] - 95s 9ms/step - loss: 0.2932\n",
            "Epoch 6/10\n",
            "10041/10041 [==============================] - 92s 9ms/step - loss: 0.2931\n",
            "Epoch 7/10\n",
            "10041/10041 [==============================] - 92s 9ms/step - loss: 0.2939\n",
            "Epoch 8/10\n",
            "10041/10041 [==============================] - 94s 9ms/step - loss: 0.2926\n",
            "Epoch 9/10\n",
            "10041/10041 [==============================] - 92s 9ms/step - loss: 0.2945\n",
            "Epoch 10/10\n",
            "10041/10041 [==============================] - 92s 9ms/step - loss: 0.2938\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaBehaTiAuLM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# testowanie sieci (nowe słowa są odrzucane)\n",
        "test_seqs = tokenizer.texts_to_sequences(test_text)\n",
        "test_seqs = pad_sequences(test_seqs, padding='post', maxlen=maxLen)\n",
        "preds = lstmModel.predict(test_seqs)\n",
        "preds[preds > 0.5] = 1\n",
        "preds[preds <= 0.5] = 0\n",
        "np.savetxt('resultsLSTM.txt', preds, fmt='%d')\n",
        "files.download('resultsLSTM.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkXBgEQWmNig",
        "colab_type": "code",
        "outputId": "ca9a22d1-8b02-4cd9-8aba-00a2a52c1307",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1108
        }
      },
      "source": [
        "# sieć LSTM na wektorach FastText (bez warstwy Embedding) - robiwektory z fasstex w czesci testowej\n",
        "\n",
        "maxLen = 40   # maksymalna długość zdania\n",
        "embeddingDim = 300   # długość wektorów (taka jest w FastText)\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_text)\n",
        "train_seqs = tokenizer.texts_to_sequences(train_text)\n",
        "#maxLen = max([len(x) for x in train_seqs])\n",
        "train_seqs = pad_sequences(train_seqs, padding='post', maxlen=maxLen)\n",
        "\n",
        "embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, embeddingDim))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "  try:\n",
        "    vector = vecModel.wv[word]\n",
        "    embedding_matrix[index] = vector\n",
        "  except KeyError:\n",
        "    continue\n",
        "\n",
        "newEmbeddingDim = 50    # długość wektorów po PCA\n",
        "pcaModel = PCA(n_components=newEmbeddingDim)\n",
        "embedding_matrix_pca = pcaModel.fit_transform(embedding_matrix)\n",
        "\n",
        "train_seqs = np.array([embedding_matrix_pca[seq,] for seq in train_seqs])\n",
        "  \n",
        "lstmModel = Sequential()\n",
        "lstmModel.add(LSTM(newEmbeddingDim))\n",
        "#lstmModel.add(Bidirectional(LSTM(newEmbeddingDim)))\n",
        "lstmModel.add(Dropout(0.5))\n",
        "lstmModel.add(Dense(1, activation='sigmoid'))\n",
        "lstmModel.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "#lstmModel.summary()\n",
        "history = lstmModel.fit(train_seqs, train_tags, epochs=30,class_weight = {0:0.1, 1:0.9})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "10041/10041 [==============================] - 11s 1ms/step - loss: 0.1159\n",
            "Epoch 2/30\n",
            "10041/10041 [==============================] - 10s 977us/step - loss: 0.1159\n",
            "Epoch 3/30\n",
            "10041/10041 [==============================] - 10s 966us/step - loss: 0.1155\n",
            "Epoch 4/30\n",
            "10041/10041 [==============================] - 10s 959us/step - loss: 0.1164\n",
            "Epoch 5/30\n",
            "10041/10041 [==============================] - 10s 961us/step - loss: 0.1111\n",
            "Epoch 6/30\n",
            "10041/10041 [==============================] - 10s 966us/step - loss: 0.1074\n",
            "Epoch 7/30\n",
            "10041/10041 [==============================] - 10s 952us/step - loss: 0.0910\n",
            "Epoch 8/30\n",
            "10041/10041 [==============================] - 10s 955us/step - loss: 0.0840\n",
            "Epoch 9/30\n",
            "10041/10041 [==============================] - 10s 958us/step - loss: 0.0806\n",
            "Epoch 10/30\n",
            "10041/10041 [==============================] - 10s 960us/step - loss: 0.0789\n",
            "Epoch 11/30\n",
            "10041/10041 [==============================] - 10s 959us/step - loss: 0.0767\n",
            "Epoch 12/30\n",
            "10041/10041 [==============================] - 10s 966us/step - loss: 0.0754\n",
            "Epoch 13/30\n",
            "10041/10041 [==============================] - 10s 986us/step - loss: 0.0747\n",
            "Epoch 14/30\n",
            "10041/10041 [==============================] - 10s 994us/step - loss: 0.0746\n",
            "Epoch 15/30\n",
            "10041/10041 [==============================] - 10s 964us/step - loss: 0.0745\n",
            "Epoch 16/30\n",
            "10041/10041 [==============================] - 10s 954us/step - loss: 0.0715\n",
            "Epoch 17/30\n",
            "10041/10041 [==============================] - 10s 961us/step - loss: 0.0708\n",
            "Epoch 18/30\n",
            "10041/10041 [==============================] - 10s 968us/step - loss: 0.0711\n",
            "Epoch 19/30\n",
            "10041/10041 [==============================] - 10s 977us/step - loss: 0.0699\n",
            "Epoch 20/30\n",
            "10041/10041 [==============================] - 10s 976us/step - loss: 0.0693\n",
            "Epoch 21/30\n",
            "10041/10041 [==============================] - 10s 971us/step - loss: 0.0685\n",
            "Epoch 22/30\n",
            "10041/10041 [==============================] - 10s 983us/step - loss: 0.0668\n",
            "Epoch 23/30\n",
            "10041/10041 [==============================] - 10s 975us/step - loss: 0.0693\n",
            "Epoch 24/30\n",
            "10041/10041 [==============================] - 10s 986us/step - loss: 0.0664\n",
            "Epoch 25/30\n",
            "10041/10041 [==============================] - 10s 979us/step - loss: 0.0670\n",
            "Epoch 26/30\n",
            "10041/10041 [==============================] - 10s 978us/step - loss: 0.0649\n",
            "Epoch 27/30\n",
            "10041/10041 [==============================] - 10s 974us/step - loss: 0.0631\n",
            "Epoch 28/30\n",
            "10041/10041 [==============================] - 10s 970us/step - loss: 0.0633\n",
            "Epoch 29/30\n",
            "10041/10041 [==============================] - 10s 975us/step - loss: 0.0607\n",
            "Epoch 30/30\n",
            "10041/10041 [==============================] - 10s 975us/step - loss: 0.0607\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0YqPplTtap2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# testowanie sieci\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(test_text)\n",
        "test_seqs = tokenizer.texts_to_sequences(test_text)\n",
        "test_seqs = pad_sequences(test_seqs, padding='post', maxlen=maxLen)\n",
        "\n",
        "embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, embeddingDim))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "  try:\n",
        "    vector = vecModel.wv[word]\n",
        "    embedding_matrix[index] = vector\n",
        "  except KeyError:\n",
        "    continue\n",
        "    \n",
        "embedding_matrix_pca = pcaModel.transform(embedding_matrix)\n",
        "test_seqs = np.array([embedding_matrix_pca[seq,] for seq in test_seqs])\n",
        "\n",
        "preds = lstmModel.predict(test_seqs)\n",
        "preds[preds > 0.5] = 1\n",
        "preds[preds <= 0.5] = 0\n",
        "np.savetxt('resultsLSTM.txt', preds, fmt='%d')\n",
        "files.download('resultsLSTM.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}